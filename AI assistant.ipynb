{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import textwrap \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assistant will keep asking for followup questions.\n",
      "Enter exit when you do not have any followup questions to stop.\n",
      "\n",
      "\n",
      " Why don't skeletons fight each other?   They don't have the guts!\n",
      "\n",
      " Why did the data scientist break up with the statistician?   Because she found him too mean!\n",
      "\n",
      " I don't have personal preferences, but the data science joke might resonate more with those in the field due to its reference to\n",
      "\"mean,\" a common statistical term, making it relatable and amusing in a professional context.\n",
      "\n",
      " It looks like your message was empty. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "system = \"You are an assistant that helps the user with any requests and questions.\\\n",
    "Answer in a brief and precise fashion.\"\n",
    "print('The assistant will keep asking for followup questions.')\n",
    "print('Enter exit when you do not have any followup questions to stop.\\n')\n",
    "user_input = []\n",
    "assistant_input = []\n",
    "user_input.append(input(\"\\nEnter your question to the AI assistant: \"))\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\":system},\n",
    "    {\"role\":\"user\", \"content\":user_input[0]}\n",
    "]\n",
    "\n",
    "while user_input[-1].upper() != 'EXIT':\n",
    "    for user, AI in zip(user_input[1:], assistant_input):\n",
    "        messages.append({'role':'assistant', 'content':AI})\n",
    "        messages.append({'role':'user', 'content':user})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages\n",
    "    )\n",
    "    print(\"\\n\", textwrap.fill(completion.choices[0].message.content, width=135))\n",
    "    # print(\"\\n\",completion.choices[0].message.content)\n",
    "    assistant_input.append(completion.choices[0].message.content)\n",
    "    user_input.append(input(\"\\nEnter your followup question to the AI assistant: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
